{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from utils import utils\n",
    "from models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "from requests import Session\n",
    "from signalr import Connection\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class_path='config/coco.names'\n",
    "config_path='config/yolov3.cfg'\n",
    "weights_path='config/yolov3.weights'\n",
    "\n",
    "img_size=416\n",
    "nms_thres=0.4\n",
    "conf_thres=0.8\n",
    "\n",
    "# Load model and weights\n",
    "model = Darknet(config_path, img_size=img_size)\n",
    "model.load_weights(weights_path)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "classes = utils.load_classes(class_path)\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "connection = Connection(\"http://127.0.0.1:8088/signalr\", session)\n",
    "conn = connection.register_hub('step5')\n",
    "connection.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(img):\n",
    "    # scale and pad image\n",
    "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
    "    imw = round(img.size[0] * ratio)\n",
    "    imh = round(img.size[1] * ratio)\n",
    "    img_transforms=transforms.Compose([transforms.Resize((imh,imw)),\n",
    "         transforms.Pad((max(int((imh-imw)/2),0), \n",
    "              max(int((imw-imh)/2),0), max(int((imh-imw)/2),0),\n",
    "              max(int((imw-imh)/2),0)), (128,128,128)),\n",
    "         transforms.ToTensor(),\n",
    "         ])\n",
    "    # convert image to Tensor\n",
    "    image_tensor = img_transforms(img).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input_img = Variable(image_tensor.type(Tensor))\n",
    "    # run inference on the model and get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_img)\n",
    "        detections = utils.non_max_suppression(detections, 80, \n",
    "                        conf_thres, nms_thres)\n",
    "    return detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciclo = np.array([np.NaN] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciclo[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciclo_temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc =  time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9731743335723877"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc - ciclo_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9731743335723877"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciclo_temp - abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False]\n",
      "[False  True False  True  True  True False  True False  True]\n",
      "[False False  True False  True False  True False  True False]\n",
      "[False False  True  True False  True  True  True  True  True]\n",
      "[ True False False  True  True False False False  True  True]\n",
      "[ True False False  True  True  True  True  True  True  True]\n",
      "[False  True False  True  True  True  True  True  True  True]\n",
      "[ True False  True  True False  True  True False  True  True]\n",
      "[ True  True  True  True  True  True False False  True  True]\n",
      "[ True  True  True  True  True  True False  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True False  True]\n",
      "[ True  True  True  True  True  True False False  True  True]\n",
      "[ True  True  True  True  True False  True  True False False]\n",
      "[ True  True  True  True  True  True  True False  True False]\n",
      "[False  True  True False False False False  True  True  True]\n",
      "[ True  True  True  True False  True  True False  True  True]\n",
      "[ True False  True False  True  True False  True  True  True]\n",
      "[ True  True  True False False  True False False False False]\n",
      "[False  True  True  True  True  True  True  True False  True]\n",
      "[ True False False False False  True  True  True  True False]\n",
      "[False  True False False False  True False  True False  True]\n",
      "[False  True False  True False  True False  True False False]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-bab41081d4e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mpilimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpilimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpilimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-766bdcea7782>\u001b[0m in \u001b[0;36mdetect_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_transforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimage_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0minput_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# run inference on the model and get detections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sort import *\n",
    "from IPython.display import clear_output\n",
    "\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "mot_tracker = Sort() \n",
    "\n",
    "status = False\n",
    "list_obj = dict()\n",
    "ciclo = np.array([False] * 10)\n",
    "ciclo_temp = time.time()\n",
    "detect_movement = False\n",
    "tick_ant = 0\n",
    "while(True):\n",
    "    tick = int(time.time() - ciclo_temp)\n",
    "    if(tick_ant != tick):\n",
    "        tick_ant = tick\n",
    "    detect_movement = False\n",
    "#for ii in range(40):\n",
    "    ret, frame2 = vid.read()\n",
    "    width = int(frame2.shape[1] * 2)\n",
    "    height = int(frame2.shape[0] * 2)\n",
    "    \n",
    "    #frame2 = cv2.resize(frame2, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "    pilimg = Image.fromarray(frame)\n",
    "    detections = detect_image(pilimg)\n",
    "\n",
    "    img = np.array(pilimg)\n",
    "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "    unpad_h = img_size - pad_y\n",
    "    unpad_w = img_size - pad_x\n",
    "    if detections is not None:\n",
    "        tracked_objects = mot_tracker.update(detections.cpu())\n",
    "\n",
    "        unique_labels = detections[:, -1].cuda().unique()\n",
    "        n_cls_preds = len(unique_labels)\n",
    "        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
    "            \n",
    "            array_pos = np.array([x1, y1, x2, y2])\n",
    "            if(obj_id not in list_obj):\n",
    "                detect_movement = True\n",
    "                list_obj[obj_id] =array_pos \n",
    "                \n",
    "            else:\n",
    "                if((np.abs(np.subtract(list_obj[obj_id], array_pos)) > 5).any()):\n",
    "                    detect_movement = True\n",
    "                    list_obj[obj_id] =array_pos                    \n",
    "                \n",
    "            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
    "            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
    "            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
    "            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
    "\n",
    "            color = colors[int(obj_id) % len(colors)]\n",
    "            color = [i * 255 for i in color]\n",
    "            cls = classes[int(cls_pred)]\n",
    "            cv2.rectangle(frame2, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
    "            cv2.rectangle(frame2, (x1, y1-35), (x1+len(cls)*19+60, y1), color, -1)\n",
    "            cv2.putText(frame2, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "       \n",
    "    if( tick >=9):\n",
    "        ciclo[9] = detect_movement\n",
    "        total = ciclo.sum()\n",
    "        if(total>=9):\n",
    "            conn.server.invoke('SetMovimento', 'Intenso')\n",
    "        elif(total>=5):\n",
    "            conn.server.invoke('SetMovimento', 'Normal')\n",
    "        else:\n",
    "            conn.server.invoke('SetMovimento', 'Parado')\n",
    "            \n",
    "        ciclo = np.array([False] * 10)\n",
    "        ciclo_temp = time.time()\n",
    "       \n",
    "    else:\n",
    "        ciclo[tick] = detect_movement\n",
    "                \n",
    "    cv2.imshow('Camera',  frame2)\n",
    "    if cv2.waitKey(1) != -1:\n",
    "        break\n",
    "    cls_pred\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(np.subtract(list_obj[obj_id],abc)) > 3).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.66034746, 177.61941607, 311.5106159 , 325.0538485 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
